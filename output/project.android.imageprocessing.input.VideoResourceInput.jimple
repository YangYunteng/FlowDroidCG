public class project.android.imageprocessing.input.VideoResourceInput extends project.android.imageprocessing.input.GLTextureOutputRenderer implements android.graphics.SurfaceTexture$OnFrameAvailableListener
{
    public static final java.lang.String UNIFORM_CAM_MATRIX;
    public android.content.Context context;
    public int id;
    public float[] matrix;
    public int matrixHandle;
    public android.media.MediaPlayer player;
    public boolean ready;
    public boolean startWhenReady;
    public android.graphics.SurfaceTexture videoTex;
    public android.opengl.GLSurfaceView view;

    public void <init>(android.opengl.GLSurfaceView, android.content.Context, int)
    {
        android.content.Context $r2;
        android.opengl.GLSurfaceView $r1;
        int $i0, $i1;
        float[] $r3;
        android.media.MediaPlayer $r4;
        project.android.imageprocessing.input.VideoResourceInput r0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        $r1 := @parameter0: android.opengl.GLSurfaceView;

        $r2 := @parameter1: android.content.Context;

        $i0 := @parameter2: int;

        specialinvoke r0.<project.android.imageprocessing.input.GLTextureOutputRenderer: void <init>()>();

        $r3 = newarray (float)[16];

        r0.<project.android.imageprocessing.input.VideoResourceInput: float[] matrix> = $r3;

        r0.<project.android.imageprocessing.input.VideoResourceInput: android.opengl.GLSurfaceView view> = $r1;

        $r4 = staticinvoke <android.media.MediaPlayer: android.media.MediaPlayer create(android.content.Context,int)>($r2, $i0);

        r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player> = $r4;

        r0.<project.android.imageprocessing.input.VideoResourceInput: android.content.Context context> = $r2;

        r0.<project.android.imageprocessing.input.VideoResourceInput: int id> = $i0;

        r0.<project.android.imageprocessing.input.VideoResourceInput: boolean startWhenReady> = 0;

        r0.<project.android.imageprocessing.input.VideoResourceInput: boolean ready> = 0;

        $r4 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        $i0 = virtualinvoke $r4.<android.media.MediaPlayer: int getVideoWidth()>();

        $r4 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        $i1 = virtualinvoke $r4.<android.media.MediaPlayer: int getVideoHeight()>();

        virtualinvoke r0.<project.android.imageprocessing.GLRenderer: void setRenderSize(int,int)>($i0, $i1);

        return;
    }

    private void bindTexture()
    {
        int $i0, $i1;
        project.android.imageprocessing.input.VideoResourceInput r0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        $i0 = 33984;

        staticinvoke <android.opengl.GLES20: void glActiveTexture(int)>($i0);

        $i0 = r0.<project.android.imageprocessing.GLRenderer: int texture_in>;

        $i1 = 36197;

        staticinvoke <android.opengl.GLES20: void glBindTexture(int,int)>($i1, $i0);

        return;
    }

    public void destroy()
    {
        int[] $r1;
        int $i0;
        android.media.MediaPlayer $r2;
        project.android.imageprocessing.input.VideoResourceInput r0;
        boolean $z0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        specialinvoke r0.<project.android.imageprocessing.input.GLTextureOutputRenderer: void destroy()>();

        $r2 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        $z0 = virtualinvoke $r2.<android.media.MediaPlayer: boolean isPlaying()>();

        if $z0 == 0 goto label1;

        $r2 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        virtualinvoke $r2.<android.media.MediaPlayer: void stop()>();

        $r2 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        virtualinvoke $r2.<android.media.MediaPlayer: void release()>();

        r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player> = null;

        r0.<project.android.imageprocessing.input.VideoResourceInput: boolean ready> = 0;

     label1:
        $i0 = r0.<project.android.imageprocessing.GLRenderer: int texture_in>;

        if $i0 == 0 goto label2;

        $r1 = newarray (int)[1];

        $r1[0] = $i0;

        staticinvoke <android.opengl.GLES20: void glDeleteTextures(int,int[],int)>(1, $r1, 0);

        r0.<project.android.imageprocessing.GLRenderer: int texture_in> = 0;

     label2:
        return;
    }

    public void drawFrame()
    {
        android.graphics.SurfaceTexture $r1;
        project.android.imageprocessing.input.VideoResourceInput r0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        $r1 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.graphics.SurfaceTexture videoTex>;

        virtualinvoke $r1.<android.graphics.SurfaceTexture: void updateTexImage()>();

        specialinvoke r0.<project.android.imageprocessing.input.GLTextureOutputRenderer: void drawFrame()>();

        return;
    }

    public java.lang.String getFragmentShader()
    {
        project.android.imageprocessing.input.VideoResourceInput r0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        return "#extension GL_OES_EGL_image_external : require\nprecision mediump float;\nuniform samplerExternalOES u_Texture0;\nvarying vec2 v_TexCoord;\nvoid main() {\n   gl_FragColor = texture2D(u_Texture0, v_TexCoord);\n}\n";
    }

    public java.lang.String getVertexShader()
    {
        project.android.imageprocessing.input.VideoResourceInput r0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        return "uniform mat4 u_Matrix;\nattribute vec4 a_Position;\nattribute vec2 a_TexCoord;\nvarying vec2 v_TexCoord;\nvoid main() {\n   vec4 texPos = u_Matrix * vec4(a_TexCoord, 1, 1);\n   v_TexCoord = texPos.xy;\n   gl_Position = a_Position;\n}\n";
    }

    public void initShaderHandles()
    {
        int $i0;
        project.android.imageprocessing.input.VideoResourceInput r0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        specialinvoke r0.<project.android.imageprocessing.GLRenderer: void initShaderHandles()>();

        $i0 = r0.<project.android.imageprocessing.GLRenderer: int programHandle>;

        $i0 = staticinvoke <android.opengl.GLES20: int glGetUniformLocation(int,java.lang.String)>($i0, "u_Matrix");

        r0.<project.android.imageprocessing.input.VideoResourceInput: int matrixHandle> = $i0;

        return;
    }

    public void initWithGLContext()
    {
        java.io.PrintWriter $r9;
        android.content.Context $r1;
        android.graphics.SurfaceTexture $r7, $r10;
        android.view.Surface $r11;
        java.io.StringWriter $r4, $r8;
        android.media.MediaPlayer $r2;
        project.android.imageprocessing.input.VideoResourceInput r0;
        java.lang.Exception $r3;
        int[] $r6;
        int $i0, $i1;
        java.lang.String $r5;
        boolean $z0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        r0.<project.android.imageprocessing.input.VideoResourceInput: boolean ready> = 0;

     label1:
        $r1 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.content.Context context>;

        $i0 = r0.<project.android.imageprocessing.input.VideoResourceInput: int id>;

        $r2 = staticinvoke <android.media.MediaPlayer: android.media.MediaPlayer create(android.content.Context,int)>($r1, $i0);

        r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player> = $r2;

     label2:
        goto label4;

     label3:
        $r3 := @caughtexception;

        staticinvoke <android.util.Log: int e(java.lang.String,java.lang.String)>("VideoPlayer", "Failed to load video");

        $r8 = new java.io.StringWriter;

        $r4 = $r8;

        specialinvoke $r8.<java.io.StringWriter: void <init>()>();

        $r9 = new java.io.PrintWriter;

        specialinvoke $r9.<java.io.PrintWriter: void <init>(java.io.Writer)>($r4);

        virtualinvoke $r3.<java.lang.Exception: void printStackTrace(java.io.PrintWriter)>($r9);

        $r5 = virtualinvoke $r4.<java.io.StringWriter: java.lang.String toString()>();

        staticinvoke <android.util.Log: int e(java.lang.String,java.lang.String)>("VideoPlayer", $r5);

        $r2 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        virtualinvoke $r2.<android.media.MediaPlayer: void release()>();

     label4:
        $r2 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        $i0 = virtualinvoke $r2.<android.media.MediaPlayer: int getVideoWidth()>();

        $r2 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        $i1 = virtualinvoke $r2.<android.media.MediaPlayer: int getVideoHeight()>();

        virtualinvoke r0.<project.android.imageprocessing.GLRenderer: void setRenderSize(int,int)>($i0, $i1);

        specialinvoke r0.<project.android.imageprocessing.GLRenderer: void initWithGLContext()>();

        $r6 = newarray (int)[1];

        staticinvoke <android.opengl.GLES20: void glGenTextures(int,int[],int)>(1, $r6, 0);

        $i0 = $r6[0];

        $i1 = 36197;

        staticinvoke <android.opengl.GLES20: void glBindTexture(int,int)>($i1, $i0);

        $i0 = 36197;

        staticinvoke <android.opengl.GLES20: void glTexParameterf(int,int,float)>($i0, 10241, 9729.0F);

        $i0 = 36197;

        staticinvoke <android.opengl.GLES20: void glTexParameterf(int,int,float)>($i0, 10240, 9729.0F);

        $i0 = 36197;

        $i1 = 33071;

        staticinvoke <android.opengl.GLES20: void glTexParameteri(int,int,int)>($i0, 10242, $i1);

        $i0 = 36197;

        $i1 = 33071;

        staticinvoke <android.opengl.GLES20: void glTexParameteri(int,int,int)>($i0, 10243, $i1);

        $i0 = $r6[0];

        r0.<project.android.imageprocessing.GLRenderer: int texture_in> = $i0;

        $r10 = new android.graphics.SurfaceTexture;

        $i0 = r0.<project.android.imageprocessing.GLRenderer: int texture_in>;

        specialinvoke $r10.<android.graphics.SurfaceTexture: void <init>(int)>($i0);

        r0.<project.android.imageprocessing.input.VideoResourceInput: android.graphics.SurfaceTexture videoTex> = $r10;

        $r7 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.graphics.SurfaceTexture videoTex>;

        virtualinvoke $r7.<android.graphics.SurfaceTexture: void setOnFrameAvailableListener(android.graphics.SurfaceTexture$OnFrameAvailableListener)>(r0);

        $r11 = new android.view.Surface;

        $r7 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.graphics.SurfaceTexture videoTex>;

        specialinvoke $r11.<android.view.Surface: void <init>(android.graphics.SurfaceTexture)>($r7);

        $r2 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        virtualinvoke $r2.<android.media.MediaPlayer: void setSurface(android.view.Surface)>($r11);

        r0.<project.android.imageprocessing.input.VideoResourceInput: boolean ready> = 1;

        $z0 = r0.<project.android.imageprocessing.input.VideoResourceInput: boolean startWhenReady>;

        if $z0 == 0 goto label5;

        $r2 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        virtualinvoke $r2.<android.media.MediaPlayer: void start()>();

     label5:
        return;

        catch java.lang.Exception from label1 to label2 with label3;
    }

    public boolean isPlaying()
    {
        android.media.MediaPlayer $r1;
        project.android.imageprocessing.input.VideoResourceInput r0;
        boolean $z0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        $r1 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        $z0 = virtualinvoke $r1.<android.media.MediaPlayer: boolean isPlaying()>();

        return $z0;
    }

    public void onFrameAvailable(android.graphics.SurfaceTexture)
    {
        android.graphics.SurfaceTexture $r1;
        project.android.imageprocessing.input.VideoResourceInput r0;
        android.opengl.GLSurfaceView $r2;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        $r1 := @parameter0: android.graphics.SurfaceTexture;

        virtualinvoke r0.<project.android.imageprocessing.input.GLTextureOutputRenderer: void markAsDirty()>();

        $r2 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.opengl.GLSurfaceView view>;

        virtualinvoke $r2.<android.opengl.GLSurfaceView: void requestRender()>();

        return;
    }

    public void passShaderValues()
    {
        android.graphics.SurfaceTexture $r3;
        java.nio.FloatBuffer $r1;
        java.nio.FloatBuffer[] $r2;
        int $i0, $i1;
        float[] $r4;
        project.android.imageprocessing.input.VideoResourceInput r0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        $r1 = r0.<project.android.imageprocessing.GLRenderer: java.nio.FloatBuffer renderVertices>;

        virtualinvoke $r1.<java.nio.FloatBuffer: java.nio.Buffer position(int)>(0);

        $i0 = r0.<project.android.imageprocessing.GLRenderer: int positionHandle>;

        $r1 = r0.<project.android.imageprocessing.GLRenderer: java.nio.FloatBuffer renderVertices>;

        staticinvoke <android.opengl.GLES20: void glVertexAttribPointer(int,int,int,boolean,int,java.nio.Buffer)>($i0, 2, 5126, 0, 8, $r1);

        $i0 = r0.<project.android.imageprocessing.GLRenderer: int positionHandle>;

        staticinvoke <android.opengl.GLES20: void glEnableVertexAttribArray(int)>($i0);

        $r2 = r0.<project.android.imageprocessing.GLRenderer: java.nio.FloatBuffer[] textureVertices>;

        $i0 = r0.<project.android.imageprocessing.GLRenderer: int curRotation>;

        $r1 = $r2[$i0];

        virtualinvoke $r1.<java.nio.FloatBuffer: java.nio.Buffer position(int)>(0);

        $i0 = r0.<project.android.imageprocessing.GLRenderer: int texCoordHandle>;

        $r2 = r0.<project.android.imageprocessing.GLRenderer: java.nio.FloatBuffer[] textureVertices>;

        $i1 = r0.<project.android.imageprocessing.GLRenderer: int curRotation>;

        $r1 = $r2[$i1];

        staticinvoke <android.opengl.GLES20: void glVertexAttribPointer(int,int,int,boolean,int,java.nio.Buffer)>($i0, 2, 5126, 0, 8, $r1);

        $i0 = r0.<project.android.imageprocessing.GLRenderer: int texCoordHandle>;

        staticinvoke <android.opengl.GLES20: void glEnableVertexAttribArray(int)>($i0);

        specialinvoke r0.<project.android.imageprocessing.input.VideoResourceInput: void bindTexture()>();

        $i0 = r0.<project.android.imageprocessing.GLRenderer: int textureHandle>;

        staticinvoke <android.opengl.GLES20: void glUniform1i(int,int)>($i0, 0);

        $r3 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.graphics.SurfaceTexture videoTex>;

        $r4 = r0.<project.android.imageprocessing.input.VideoResourceInput: float[] matrix>;

        virtualinvoke $r3.<android.graphics.SurfaceTexture: void getTransformMatrix(float[])>($r4);

        $i0 = r0.<project.android.imageprocessing.input.VideoResourceInput: int matrixHandle>;

        $r4 = r0.<project.android.imageprocessing.input.VideoResourceInput: float[] matrix>;

        staticinvoke <android.opengl.GLES20: void glUniformMatrix4fv(int,int,boolean,float[],int)>($i0, 1, 0, $r4, 0);

        return;
    }

    public void setVideoSource(int)
    {
        int $i0;
        project.android.imageprocessing.input.VideoResourceInput r0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        $i0 := @parameter0: int;

        r0.<project.android.imageprocessing.input.VideoResourceInput: int id> = $i0;

        return;
    }

    public void startWhenReady()
    {
        android.media.MediaPlayer $r1;
        project.android.imageprocessing.input.VideoResourceInput r0;
        boolean $z0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        $z0 = r0.<project.android.imageprocessing.input.VideoResourceInput: boolean ready>;

        if $z0 == 0 goto label1;

        $r1 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        virtualinvoke $r1.<android.media.MediaPlayer: void start()>();

        return;

     label1:
        r0.<project.android.imageprocessing.input.VideoResourceInput: boolean startWhenReady> = 1;

        return;
    }

    public void stop()
    {
        android.media.MediaPlayer $r1;
        project.android.imageprocessing.input.VideoResourceInput r0;

        r0 := @this: project.android.imageprocessing.input.VideoResourceInput;

        $r1 = r0.<project.android.imageprocessing.input.VideoResourceInput: android.media.MediaPlayer player>;

        virtualinvoke $r1.<android.media.MediaPlayer: void pause()>();

        return;
    }

    public static void <clinit>()
    {
        <project.android.imageprocessing.input.VideoResourceInput: java.lang.String UNIFORM_CAM_MATRIX> = "u_Matrix";

        return;
    }
}
